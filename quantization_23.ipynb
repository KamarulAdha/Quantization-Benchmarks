{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/workspace/data/radar/23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(os.path.join(directory, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11520"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11520/11520 [25:55<00:00,  7.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_path in tqdm(file_paths):\n",
    "    # print(file_path)\n",
    "    file_name = file_path.split(\"/\")[-1].strip().split(\".\")[0].strip()\n",
    "    \n",
    "    sample_df = pd.read_csv(file_path, header=None, skiprows=10, nrows=1)\n",
    "    num_columns = len(sample_df.columns)\n",
    "\n",
    "    matrix_df = pd.read_csv(\n",
    "        file_path,\n",
    "        header=None,\n",
    "        skiprows=10,           # skip Excel rows 1–10\n",
    "        usecols=range(num_columns),     # use all available columns\n",
    "    )\n",
    "\n",
    "    matrix = matrix_df.to_numpy()\n",
    "\n",
    "    indices = np.argwhere(matrix != 0)\n",
    "    values = matrix[indices[:, 0], indices[:, 1]]\n",
    "    shape = matrix.shape\n",
    "\n",
    "    sparse_tensor = {\n",
    "        \"indices\": indices.tolist(),\n",
    "        \"values\": values.tolist(),\n",
    "        \"shape\": list(shape)\n",
    "    }\n",
    "\n",
    "    with open(f\"/workspace/data/radar_quantized/23_quantized/{file_name}.json\", \"w\") as f:\n",
    "        json.dump(sparse_tensor, f, indent=2)\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11520/11520 [08:15<00:00, 23.24it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse\n",
    "\n",
    "# Path to the directory\n",
    "directory = '/workspace/data/radar/23'\n",
    "output_directory = \"/workspace/data/radar_quantized/23_quantized\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get all files in the directory\n",
    "file_paths = glob.glob(os.path.join(directory, '*'))\n",
    "\n",
    "# Process each file\n",
    "for file_path in tqdm(file_paths):\n",
    "    # Extract file name\n",
    "    file_name = file_path.split(\"/\")[-1].strip().split(\".\")[0].strip()\n",
    "    \n",
    "    try:\n",
    "        # Read sample to determine column count\n",
    "        sample_df = pd.read_csv(file_path, header=None, skiprows=10, nrows=1)\n",
    "        num_columns = len(sample_df.columns)\n",
    "\n",
    "        # Read full dataset\n",
    "        matrix_df = pd.read_csv(\n",
    "            file_path,\n",
    "            header=None,\n",
    "            skiprows=10,           # skip Excel rows 1–10\n",
    "            usecols=range(num_columns)  # use all available columns\n",
    "        )\n",
    "\n",
    "        # Convert to numpy array\n",
    "        matrix = matrix_df.to_numpy()\n",
    "        \n",
    "        # Convert to CSR sparse matrix format\n",
    "        sparse_matrix = sparse.csr_matrix(matrix)\n",
    "        \n",
    "        # Save to compressed NPZ file\n",
    "        output_path = os.path.join(output_directory, f\"{file_name}.npz\")\n",
    "        sparse.save_npz(output_path, sparse_matrix)\n",
    "        \n",
    "        # Optionally print statistics\n",
    "        # print(f\"Processed {file_name}, shape: {matrix.shape}, \" \n",
    "        #       f\"density: {sparse_matrix.nnz/(matrix.shape[0]*matrix.shape[1]):.4f}, \"\n",
    "        #       f\"non-zeros: {sparse_matrix.nnz}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_sparse_matrix = sparse.load_npz(\"/workspace/data/radar_quantized/23_quantized/20240523_194300_Rain_001.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_matrix = sparse_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1, 0.1, 0.1, ..., 0.1, 0.1, 0.1],\n",
       "       [0.8, 0.7, 0.8, ..., 1. , 1.1, 1.1],\n",
       "       [0.9, 0.9, 0.9, ..., 1.1, 1.1, 1.2],\n",
       "       ...,\n",
       "       [4. , 4.1, 4. , ..., 2.7, 2.9, 4.6],\n",
       "       [4.7, 6. , 7. , ..., 2.5, 3.1, 5.1],\n",
       "       [4.8, 6.2, 7. , ..., 2.6, 2.8, 4.4]], shape=(300, 723))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11520/11520 [12:38<00:00, 15.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Path to the directory\n",
    "directory = '/workspace/data/radar/23'\n",
    "output_directory = \"/workspace/data/radar_quantized/23_quantized\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get all files in the directory\n",
    "file_paths = glob.glob(os.path.join(directory, '*'))\n",
    "\n",
    "# Process each file\n",
    "for file_path in tqdm(file_paths):\n",
    "    # Extract file name\n",
    "    file_name = file_path.split(\"/\")[-1].strip().split(\".\")[0].strip()\n",
    "    \n",
    "    try:\n",
    "        # Read sample to determine column count\n",
    "        sample_df = pd.read_csv(file_path, header=None, skiprows=10, nrows=1)\n",
    "        num_columns = len(sample_df.columns)\n",
    "\n",
    "        # Read full dataset\n",
    "        matrix_df = pd.read_csv(\n",
    "            file_path,\n",
    "            header=None,\n",
    "            skiprows=10,           # skip Excel rows 1–10\n",
    "            usecols=range(num_columns)  # use all available columns\n",
    "        )\n",
    "\n",
    "        # Convert to numpy array\n",
    "        matrix = matrix_df.to_numpy()\n",
    "        \n",
    "        # Create our own CSR representation\n",
    "        data = []          # Will hold non-zero values\n",
    "        indices = []       # Will hold column indices\n",
    "        indptr = [0]       # Row pointers (starting with 0)\n",
    "        \n",
    "        # Process each row\n",
    "        for row in matrix:\n",
    "            # Find non-zero elements in this row\n",
    "            row_indices = np.nonzero(row)[0]\n",
    "            row_data = row[row_indices]\n",
    "            \n",
    "            # Add this row's data and indices\n",
    "            data.extend(row_data.tolist())\n",
    "            indices.extend(row_indices.tolist())\n",
    "            \n",
    "            # Update indptr (points to end of this row/start of next)\n",
    "            indptr.append(len(data))\n",
    "        \n",
    "        # Create JSON representation\n",
    "        sparse_json = {\n",
    "            \"data\": data,\n",
    "            \"indices\": indices,\n",
    "            \"indptr\": indptr,\n",
    "            \"shape\": list(matrix.shape)\n",
    "        }\n",
    "        \n",
    "        # Save to JSON file\n",
    "        output_path = os.path.join(output_directory, f\"{file_name}.json\")\n",
    "        with open(output_path, \"w\") as f:\n",
    "            json.dump(sparse_json, f)\n",
    "        \n",
    "        # Calculate and print statistics\n",
    "        density = len(data) / (matrix.shape[0] * matrix.shape[1])\n",
    "        # print(f\"Processed {file_name}, shape: {matrix.shape}, \" \n",
    "        #       f\"density: {density:.4f}, \"\n",
    "        #       f\"non-zeros: {len(data)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torch-2.7.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (1097.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 GB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torchvision-0.22.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu128/torchaudio-2.7.0%2Bcu128-cp310-cp310-manylinux_2_28_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.8.3.14\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cublas_cu12-12.8.3.14-py3-none-manylinux_2_27_x86_64.whl (609.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m609.6/609.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.3.3.41\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufft_cu12-11.3.3.41-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.10.0 in /workspace/data/venv/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.61\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_nvrtc_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.0.11\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cufile_cu12-1.13.0.11-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 KB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparselt-cu12==0.6.3\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.8.61\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvjitlink_cu12-12.8.61-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.2/39.2 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy>=1.13.3\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.3.0\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.7.1.26\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cudnn_cu12-9.7.1.26-py3-none-manylinux_2_27_x86_64.whl (726.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m726.9/726.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.9.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_curand_cu12-10.3.9.55-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.5.7.53\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusparse_cu12-12.5.7.53-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (292.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting jinja2\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 KB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.7.2.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cusolver_cu12-11.7.2.55-py3-none-manylinux_2_27_x86_64.whl (260.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.4/260.4 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.8.57\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_cupti_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.26.2\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.8.57\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.8.55\n",
      "  Downloading https://download.pytorch.org/whl/cu128/nvidia_nvtx_cu12-12.8.55-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools>=40.8.0 in /workspace/data/venv/lib/python3.10/site-packages (from triton==3.3.0->torch) (59.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/data/venv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: numpy in /workspace/data/venv/lib/python3.10/site-packages (from torchvision) (2.2.4)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting MarkupSafe>=2.0\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.8.3.14 nvidia-cuda-cupti-cu12-12.8.57 nvidia-cuda-nvrtc-cu12-12.8.61 nvidia-cuda-runtime-cu12-12.8.57 nvidia-cudnn-cu12-9.7.1.26 nvidia-cufft-cu12-11.3.3.41 nvidia-cufile-cu12-1.13.0.11 nvidia-curand-cu12-10.3.9.55 nvidia-cusolver-cu12-11.7.2.55 nvidia-cusparse-cu12-12.5.7.53 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.8.61 nvidia-nvtx-cu12-12.8.55 sympy-1.13.3 torch-2.7.0+cu128 torchaudio-2.7.0+cu128 torchvision-0.22.0+cu128 triton-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11520/11520 [08:08<00:00, 23.60it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Path to directories\n",
    "directory = '/workspace/data/radar/23'\n",
    "output_directory = \"/workspace/data/radar_quantized/23_quantized\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get all files\n",
    "file_paths = glob.glob(os.path.join(directory, '*'))\n",
    "\n",
    "for file_path in tqdm(file_paths):\n",
    "    file_name = file_path.split(\"/\")[-1].strip().split(\".\")[0].strip()\n",
    "    \n",
    "    try:\n",
    "        # Read data as before\n",
    "        sample_df = pd.read_csv(file_path, header=None, skiprows=10, nrows=1)\n",
    "        num_columns = len(sample_df.columns)\n",
    "        \n",
    "        matrix_df = pd.read_csv(\n",
    "            file_path,\n",
    "            header=None,\n",
    "            skiprows=10,\n",
    "            usecols=range(num_columns)\n",
    "        )\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        matrix = matrix_df.to_numpy()\n",
    "        \n",
    "        # Find non-zero indices\n",
    "        indices = np.nonzero(matrix)\n",
    "        values = matrix[indices[0], indices[1]]\n",
    "        \n",
    "        # Convert to PyTorch sparse tensor\n",
    "        # First, create indices tensor (2 x nnz format)\n",
    "        i = torch.LongTensor(np.vstack(indices))\n",
    "        \n",
    "        # Then create values tensor\n",
    "        v = torch.FloatTensor(values)\n",
    "        \n",
    "        # Create sparse tensor\n",
    "        sparse_tensor = torch.sparse_coo_tensor(\n",
    "            i, v, torch.Size(matrix.shape)\n",
    "        )\n",
    "        \n",
    "        # Optional: Convert to CSR format (more efficient for some operations)\n",
    "        # sparse_tensor = sparse_tensor.to_sparse_csr()\n",
    "        \n",
    "        # Save to file (very efficient)\n",
    "        output_path = os.path.join(output_directory, f\"{file_name}.pt\")\n",
    "        torch.save(sparse_tensor, output_path)\n",
    "        \n",
    "        # print(f\"Processed {file_name}, shape: {matrix.shape}, non-zeros: {len(values)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
